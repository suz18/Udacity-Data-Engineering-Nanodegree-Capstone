{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Analysis on Immigration records\n",
    "### Udacity Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In this project, immigration records from the US National Tourism and Trade Office along with the US demographic and airport code data from other sources are pulled in for analysis purposes. Original data is first gathered and explored so that the key information can be located and specified. Then a data model is defined in order to align with the analysis purposes. The orginal data is then processed by ETL (extract, transform and load) to be dumped into the defined data model. Lastly, the analysis questions can be answered based on the data model using simple joins.  \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "import glob\n",
    "\n",
    "# Connect to Spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The data used in this project includes I94 immigration data, the US demographic data and airport code data. These data sources are grathered and processed to give insights and answer the following questions, such as:\n",
    "1. Which airport has the most immigrants coming in?\n",
    "2. Which state has the highest immigration rate?\n",
    "3. Which state has the most immigrants coming in as student? What's the immigration rate of that state?\n",
    "4. Which state has the most immigrants coming in for pleasure? What's the immigration rate of that state?   \n",
    "...\n",
    "\n",
    "The tools mainly used is Jupyter notebook with pandas and pyspark libraries. For revisit purposes, the data model after ETL can be saved in S3. For future improvement, such as making the pipeline automatic so that the data model runs every month when new immigration data comes in, Apache Airflow with schedules can be applicable for such use case. \n",
    "\n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "The data used in this project are from three diffrent sources.     \n",
    "1. I94 Immigration data:      \n",
    "This data comes from the US National Tourism and Trade Office. A sample data file is attached and is used for exploratory purpose. The real data used for analysis covers the whole year (12 months) of 2016. The data comes from [here](https://travel.trade.gov/research/reports/i94/historical/2016.html). The data provides detailed information about each collected immigration records, such as residency city, entry port, arrival date, visiting state, visa type and so on. This data is the largest among all three data sources. To better answer analysis questions, the orginal data can be aggregated to provide an appropriate granularity level of data. \n",
    "2. The US City demographic data:     \n",
    "This data comes from [OpenSoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/). The data provides information such as population, population by race for a city in the US. \n",
    "3. Airport code data:     \n",
    "The data provides airport codes, types of the airports and their corresponding cities. It comes from [here](https://datahub.io/core/airport-codes#data).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data & Cleaning Steps\n",
    "In this section data quality issues will be identified, like missing values, duplicate data, etc. Necessary steps to clean the data will also be documented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.1 Demographic Data\n",
    "The original demographic data \"us-cities-demographics.csv\" is first loaded into Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8000</td>\n",
       "      <td>40601.0000</td>\n",
       "      <td>41862.0000</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0000</td>\n",
       "      <td>30908.0000</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0000</td>\n",
       "      <td>44129.0000</td>\n",
       "      <td>49500.0000</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0000</td>\n",
       "      <td>32935.0000</td>\n",
       "      <td>2.3900</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5000</td>\n",
       "      <td>38040.0000</td>\n",
       "      <td>46799.0000</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0000</td>\n",
       "      <td>8229.0000</td>\n",
       "      <td>2.5800</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5000</td>\n",
       "      <td>88127.0000</td>\n",
       "      <td>87105.0000</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0000</td>\n",
       "      <td>33878.0000</td>\n",
       "      <td>3.1800</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6000</td>\n",
       "      <td>138040.0000</td>\n",
       "      <td>143873.0000</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0000</td>\n",
       "      <td>86253.0000</td>\n",
       "      <td>2.7300</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland     33.8000       40601.0000   \n",
       "1            Quincy  Massachusetts     41.0000       44129.0000   \n",
       "2            Hoover        Alabama     38.5000       38040.0000   \n",
       "3  Rancho Cucamonga     California     34.5000       88127.0000   \n",
       "4            Newark     New Jersey     34.6000      138040.0000   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0         41862.0000             82463           1562.0000    30908.0000   \n",
       "1         49500.0000             93629           4147.0000    32935.0000   \n",
       "2         46799.0000             84839           4819.0000     8229.0000   \n",
       "3         87105.0000            175232           5821.0000    33878.0000   \n",
       "4        143873.0000            281913           5829.0000    86253.0000   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                  2.6000         MD         Hispanic or Latino  25924  \n",
       "1                  2.3900         MA                      White  58723  \n",
       "2                  2.5800         AL                      Asian   4759  \n",
       "3                  3.1800         CA  Black or African-American  24437  \n",
       "4                  2.7300         NJ                      White  76402  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in demographic data\n",
    "fname ='us-cities-demographics.csv'\n",
    "demo_df =  pd.read_csv(fname,sep=';')\n",
    "demo_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "After an initial look at the provided demographic data, it's easily noticed that multiple records exist for a single city. It's because each record presents the population of a certain race within that single city. \n",
    "For example, let's have a look at the records for Silver Spring, Maryland.\n",
    "For Silver Spring, Maryland, there's 5 records in total with the first couple of columns having the same values. The only difference is the last two columns, race and count. Each record presents the race and the corresponding population of that race. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8000</td>\n",
       "      <td>40601.0000</td>\n",
       "      <td>41862.0000</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0000</td>\n",
       "      <td>30908.0000</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8000</td>\n",
       "      <td>40601.0000</td>\n",
       "      <td>41862.0000</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0000</td>\n",
       "      <td>30908.0000</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>MD</td>\n",
       "      <td>White</td>\n",
       "      <td>37756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8000</td>\n",
       "      <td>40601.0000</td>\n",
       "      <td>41862.0000</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0000</td>\n",
       "      <td>30908.0000</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>MD</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>21330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8000</td>\n",
       "      <td>40601.0000</td>\n",
       "      <td>41862.0000</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0000</td>\n",
       "      <td>30908.0000</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>MD</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8000</td>\n",
       "      <td>40601.0000</td>\n",
       "      <td>41862.0000</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0000</td>\n",
       "      <td>30908.0000</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>MD</td>\n",
       "      <td>Asian</td>\n",
       "      <td>8841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City     State  Median Age  Male Population  Female Population  \\\n",
       "0     Silver Spring  Maryland     33.8000       40601.0000         41862.0000   \n",
       "592   Silver Spring  Maryland     33.8000       40601.0000         41862.0000   \n",
       "1678  Silver Spring  Maryland     33.8000       40601.0000         41862.0000   \n",
       "2123  Silver Spring  Maryland     33.8000       40601.0000         41862.0000   \n",
       "2162  Silver Spring  Maryland     33.8000       40601.0000         41862.0000   \n",
       "\n",
       "      Total Population  Number of Veterans  Foreign-born  \\\n",
       "0                82463           1562.0000    30908.0000   \n",
       "592              82463           1562.0000    30908.0000   \n",
       "1678             82463           1562.0000    30908.0000   \n",
       "2123             82463           1562.0000    30908.0000   \n",
       "2162             82463           1562.0000    30908.0000   \n",
       "\n",
       "      Average Household Size State Code                               Race  \\\n",
       "0                     2.6000         MD                 Hispanic or Latino   \n",
       "592                   2.6000         MD                              White   \n",
       "1678                  2.6000         MD          Black or African-American   \n",
       "2123                  2.6000         MD  American Indian and Alaska Native   \n",
       "2162                  2.6000         MD                              Asian   \n",
       "\n",
       "      Count  \n",
       "0     25924  \n",
       "592   37756  \n",
       "1678  21330  \n",
       "2123   1084  \n",
       "2162   8841  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df[(demo_df.City == 'Silver Spring' ) & (demo_df.State == 'Maryland')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "To put it in another way, the orginal demographic data is a long dataset. To better utilize this dataset, pivot function is used to transform the original long demographic dataset into a wide one. The transformed dataset will provide one record for each city in the U.S with the population of 5 race categories, all in one entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# transform the long dataset to a wide one so that there's only one record for each city with # for each race\n",
    "demo_df = demo_df.pivot_table(index=['City', 'State', 'Median Age', 'Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born', 'Average Household Size', 'State Code'],columns='Race', values='Count').reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Let's have a look at the records for Silver Spring, Maryland again after transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Race</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black or African-American</th>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8000</td>\n",
       "      <td>40601.0000</td>\n",
       "      <td>41862.0000</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0000</td>\n",
       "      <td>30908.0000</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>MD</td>\n",
       "      <td>1084.0000</td>\n",
       "      <td>8841.0000</td>\n",
       "      <td>21330.0000</td>\n",
       "      <td>25924.0000</td>\n",
       "      <td>37756.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Race           City     State  Median Age  Male Population  Female Population  \\\n",
       "489   Silver Spring  Maryland     33.8000       40601.0000         41862.0000   \n",
       "\n",
       "Race  Total Population  Number of Veterans  Foreign-born  \\\n",
       "489              82463           1562.0000    30908.0000   \n",
       "\n",
       "Race  Average Household Size State Code  American Indian and Alaska Native  \\\n",
       "489                   2.6000         MD                          1084.0000   \n",
       "\n",
       "Race     Asian  Black or African-American  Hispanic or Latino      White  \n",
       "489  8841.0000                 21330.0000          25924.0000 37756.0000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df[(demo_df.City == 'Silver Spring' ) & (demo_df.State == 'Maryland')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now there's only one record for Silver Spring, Maryland with 5 races and their respective populations. Let's check to see if there's any duplicated records for cities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Race</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>American Indian and Alaska Native</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black or African-American</th>\n",
       "      <th>Hispanic or Latino</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, State, Median Age, Male Population, Female Population, Total Population, Number of Veterans, Foreign-born, Average Household Size, State Code, American Indian and Alaska Native, Asian, Black or African-American, Hispanic or Latino, White]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df[demo_df.duplicated(subset=['City','State']) == True ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "No duplicated records exist for cities. This concludes the cleaning and pre-processing of demographic data.     \n",
    "Please note, the pre-processed demographic data is on city-level. To be linked up with other data sources in the following steps, state-level information is preferred, but let's just leave it for now, because city-level information may provide more insights later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.2 Airport Code data\n",
    "The original airport code data \"airport-codes_csv.csv\" is first loaded into Python. \n",
    "\n",
    "From the provided airport code dataset, airports that are not based in the U.S. or that are already closed are not of interest and will be filtered out from the dataset. In addition, a new variable 'state_id' is derived based on 'iso_region' in order to make it easier when joinging with other tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport       11.0000   \n",
       "1  00AA  small_airport                Aero B Ranch Airport     3435.0000   \n",
       "2  00AK  small_airport                        Lowell Field      450.0000   \n",
       "3  00AL  small_airport                        Epps Airpark      820.0000   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport      237.0000   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in airport code data \n",
    "fname ='airport-codes_csv.csv'\n",
    "air_df =  pd.read_csv(fname)\n",
    "air_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'PR', 'MH', 'MP', 'GU', 'SO', 'AQ', 'GB', 'PG', 'AD', 'SD',\n",
       "       'SA', 'AE', 'SS', 'ES', 'CN', 'AF', 'LK', 'SB', 'CO', 'AU', 'MG',\n",
       "       'TD', 'AL', 'AM', 'MX', 'MZ', 'PW', 'NR', 'AO', 'AR', 'AS', 'AT',\n",
       "       'ZZ', 'GA', 'AZ', 'BA', 'BB', 'BE', 'DE', 'BF', 'BG', 'GL', 'BH',\n",
       "       'BI', 'IS', 'BJ', 'OM', 'XK', 'BM', 'KE', 'PH', 'BO', 'BR', 'BS',\n",
       "       'CV', 'BW', 'FJ', 'BY', 'UA', 'LR', 'BZ', 'CA', 'CD', 'CF', 'CG',\n",
       "       'MR', 'CH', 'CL', 'CM', 'MA', 'CR', 'CU', 'CY', 'CZ', 'SK', 'PA',\n",
       "       'DZ', 'ID', 'GH', 'RU', 'CI', 'DK', 'NG', 'DO', 'NE', 'HR', 'TN',\n",
       "       'TG', 'EC', 'EE', 'FI', 'EG', 'GG', 'JE', 'IM', 'FK', 'EH', 'NL',\n",
       "       'IE', 'FO', 'LU', 'NO', 'PL', 'ER', 'MN', 'PT', 'SE', 'ET', 'LV',\n",
       "       'LT', 'ZA', 'SZ', 'GQ', 'SH', 'MU', 'IO', 'ZM', 'FM', 'KM', 'YT',\n",
       "       'RE', 'TF', 'ST', 'FR', 'SC', 'ZW', 'MW', 'LS', nan, 'ML', 'GM',\n",
       "       'GE', 'GF', 'SL', 'GW', 'GN', 'SN', 'GR', 'GT', 'TZ', 'GY', 'SR',\n",
       "       'DJ', 'HK', 'LY', 'HN', 'VN', 'KZ', 'RW', 'HT', 'HU', 'UG', 'TL',\n",
       "       'IL', 'IN', 'IQ', 'IR', 'JP', 'IT', 'JM', 'JO', 'KG', 'BD', 'KI',\n",
       "       'KH', 'KP', 'KR', 'KW', 'LA', 'MY', 'PM', 'SI', 'PS', 'MT', 'MC',\n",
       "       'RO', 'LI', 'TR', 'MD', 'MK', 'GI', 'RS', 'ME', 'TC', 'GD', 'MM',\n",
       "       'NI', 'SV', 'MF', 'MV', 'KY', 'NC', 'CK', 'TO', 'TV', 'NU', 'WF',\n",
       "       'NP', 'WS', 'PF', 'VU', 'NZ', 'LB', 'PK', 'SY', 'QA', 'YE', 'UM',\n",
       "       'PE', 'TH', 'PY', 'TW', 'SG', 'VI', 'SM', 'UY', 'VE', 'AG', 'DM',\n",
       "       'GP', 'MQ', 'BL', 'TJ', 'KN', 'LC', 'TM', 'AW', 'BQ', 'CW', 'SX',\n",
       "       'AI', 'MS', 'TT', 'VG', 'VC', 'UZ', 'VA', 'MO', 'BT', 'BN', 'CC',\n",
       "       'CX', 'NF'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_df.iso_country.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The provided airport code data provides airport code and other info for airports all over the world, but only the ones in the U.S. are of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['heliport', 'small_airport', 'closed', 'seaplane_base',\n",
       "       'balloonport', 'medium_airport', 'large_airport'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_df.type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data covers different types of airports and the ones that are closed are not of interest either, which need to be removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "After inspection, the iata_code in this data can be linked together with I94PORT in immigration data, but the NaN records need to be removed first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'UTK', 'OCA', ..., 'SHE', 'YNJ', 'YKH'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "air_df.iata_code.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Overall, to clean and pre-process airport code data, the steps are as bellow:\n",
    "1. Only select records where the airport is located in the U.S. and the type of the airport is not closed.\n",
    "2. Remove the records where iata_code is NaN. \n",
    "3. Derive state information based on column \"iso_region\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>07FA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Ocean Reef Club Airport</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-FL</td>\n",
       "      <td>Key Largo</td>\n",
       "      <td>07FA</td>\n",
       "      <td>OCA</td>\n",
       "      <td>07FA</td>\n",
       "      <td>-80.274803161621, 25.325399398804</td>\n",
       "      <td>FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Pilot Station Airport</td>\n",
       "      <td>305.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Pilot Station</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PQS</td>\n",
       "      <td>0AK</td>\n",
       "      <td>-162.899994, 61.934601</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>0CO2</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Crested Butte Airpark</td>\n",
       "      <td>8980.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-CO</td>\n",
       "      <td>Crested Butte</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>CSE</td>\n",
       "      <td>0CO2</td>\n",
       "      <td>-106.928341, 38.851918</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>0TE7</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>LBJ Ranch Airport</td>\n",
       "      <td>1515.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-TX</td>\n",
       "      <td>Johnson City</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>JCY</td>\n",
       "      <td>0TE7</td>\n",
       "      <td>-98.62249755859999, 30.251800537100003</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>13MA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Metropolitan Airport</td>\n",
       "      <td>418.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-MA</td>\n",
       "      <td>Palmer</td>\n",
       "      <td>13MA</td>\n",
       "      <td>PMX</td>\n",
       "      <td>13MA</td>\n",
       "      <td>-72.31140136719999, 42.223300933800004</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ident           type                     name  elevation_ft continent  \\\n",
       "440   07FA  small_airport  Ocean Reef Club Airport        8.0000       NaN   \n",
       "594    0AK  small_airport    Pilot Station Airport      305.0000       NaN   \n",
       "673   0CO2  small_airport    Crested Butte Airpark     8980.0000       NaN   \n",
       "1088  0TE7  small_airport        LBJ Ranch Airport     1515.0000       NaN   \n",
       "1402  13MA  small_airport     Metropolitan Airport      418.0000       NaN   \n",
       "\n",
       "     iso_country iso_region   municipality gps_code iata_code local_code  \\\n",
       "440           US      US-FL      Key Largo     07FA       OCA       07FA   \n",
       "594           US      US-AK  Pilot Station      NaN       PQS        0AK   \n",
       "673           US      US-CO  Crested Butte     0CO2       CSE       0CO2   \n",
       "1088          US      US-TX   Johnson City     0TE7       JCY       0TE7   \n",
       "1402          US      US-MA         Palmer     13MA       PMX       13MA   \n",
       "\n",
       "                                 coordinates state_id  \n",
       "440        -80.274803161621, 25.325399398804       FL  \n",
       "594                   -162.899994, 61.934601       AK  \n",
       "673                   -106.928341, 38.851918       CO  \n",
       "1088  -98.62249755859999, 30.251800537100003       TX  \n",
       "1402  -72.31140136719999, 42.223300933800004       MA  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only select airports that are in the U.S. and are not closed \n",
    "air_df = air_df[(air_df.iso_country == 'US') & (air_df.type != 'closed')]\n",
    "\n",
    "# drop records where iata_code is null\n",
    "air_df = air_df.dropna(0,subset = ['iata_code'])\n",
    "\n",
    "# make a new column state_id from iso_region\n",
    "air_df['state_id'] = air_df.iso_region.str[3:]\n",
    "air_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>state_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ident, type, name, elevation_ft, continent, iso_country, iso_region, municipality, gps_code, iata_code, local_code, coordinates, state_id]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iata_code is unique, can function as primary key for this table \n",
    "air_df[air_df.duplicated(subset=['iata_code']) == True ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "After processing, it seems that column 'iata_code' is unqiue and not null, which can be used as primary key. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 2.3 Immigration data\n",
    "First the sample immigration data is loaded into Python for exploratory purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2027561</th>\n",
       "      <td>4084316.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>209.0000</td>\n",
       "      <td>209.0000</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>HI</td>\n",
       "      <td>20573.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0000</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>nan</td>\n",
       "      <td>JL</td>\n",
       "      <td>56582674633.0000</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171295</th>\n",
       "      <td>4422636.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>582.0000</td>\n",
       "      <td>582.0000</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>TX</td>\n",
       "      <td>20568.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0000</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>nan</td>\n",
       "      <td>*GA</td>\n",
       "      <td>94361995930.0000</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589494</th>\n",
       "      <td>1195600.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>148.0000</td>\n",
       "      <td>112.0000</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>FL</td>\n",
       "      <td>20571.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0000</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>nan</td>\n",
       "      <td>LH</td>\n",
       "      <td>55780468433.0000</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631158</th>\n",
       "      <td>5291768.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>297.0000</td>\n",
       "      <td>297.0000</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>CA</td>\n",
       "      <td>20581.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0000</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>nan</td>\n",
       "      <td>QR</td>\n",
       "      <td>94789696030.0000</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3032257</th>\n",
       "      <td>985523.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>111.0000</td>\n",
       "      <td>111.0000</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0000</td>\n",
       "      <td>3.0000</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>nan</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0000</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42322572633.0000</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               cicid     i94yr  i94mon   i94cit   i94res i94port    arrdate  \\\n",
       "2027561 4084316.0000 2016.0000  4.0000 209.0000 209.0000     HHW 20566.0000   \n",
       "2171295 4422636.0000 2016.0000  4.0000 582.0000 582.0000     MCA 20567.0000   \n",
       "589494  1195600.0000 2016.0000  4.0000 148.0000 112.0000     OGG 20551.0000   \n",
       "2631158 5291768.0000 2016.0000  4.0000 297.0000 297.0000     LOS 20572.0000   \n",
       "3032257  985523.0000 2016.0000  4.0000 111.0000 111.0000     CHM 20550.0000   \n",
       "\n",
       "         i94mode i94addr    depdate   ...     entdepu  matflag   biryear  \\\n",
       "2027561   1.0000      HI 20573.0000   ...         nan        M 1955.0000   \n",
       "2171295   1.0000      TX 20568.0000   ...         nan        M 1990.0000   \n",
       "589494    1.0000      FL 20571.0000   ...         nan        M 1940.0000   \n",
       "2631158   1.0000      CA 20581.0000   ...         nan        M 1991.0000   \n",
       "3032257   3.0000      NY 20553.0000   ...         nan        M 1997.0000   \n",
       "\n",
       "          dtaddto gender insnum airline           admnum  fltno visatype  \n",
       "2027561  07202016      F    nan      JL 56582674633.0000  00782       WT  \n",
       "2171295  10222016      M    nan     *GA 94361995930.0000  XBLNG       B2  \n",
       "589494   07052016      M    nan      LH 55780468433.0000  00464       WT  \n",
       "2631158  10272016      M    nan      QR 94789696030.0000  00739       B2  \n",
       "3032257  07042016      F    nan     NaN 42322572633.0000   LAND       WT  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'immigration_data_sample.csv'\n",
    "imm_df =  pd.read_csv(fname, index_col =0)\n",
    "imm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate',\n",
       "       'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count',\n",
       "       'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu',\n",
       "       'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline',\n",
       "       'admnum', 'fltno', 'visatype'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For the purpose of the project, we are only interested to know the immigration entry records via air, so data will be filter by i94mode = 1 first.     \n",
    "\n",
    "The real immigration data provided covers all 12 months of year 2016 and is very large to process. For the purpose of the project, this level of granularity the orginal data presents is unnecessary. Therefore, we can group by the records and keep the level of information that is aligned with the purpose of the project. \n",
    "\n",
    "The sample immigration data is to be grouped by visa category, airport, state, month and year. \n",
    "The same processing will also be utilized when dealing with the whole immigration data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94visa</th>\n",
       "      <th>i94port</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>ATL</td>\n",
       "      <td>AL</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>ATL</td>\n",
       "      <td>CA</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>ATL</td>\n",
       "      <td>GA</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>3.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>ATL</td>\n",
       "      <td>IL</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>ATL</td>\n",
       "      <td>IN</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>2016.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94visa i94port i94addr  i94mon     i94yr  count\n",
       "0   1.0000     ATL      AL  4.0000 2016.0000 1.0000\n",
       "1   1.0000     ATL      CA  4.0000 2016.0000 1.0000\n",
       "2   1.0000     ATL      GA  4.0000 2016.0000 3.0000\n",
       "3   1.0000     ATL      IL  4.0000 2016.0000 1.0000\n",
       "4   1.0000     ATL      IN  4.0000 2016.0000 1.0000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imm_df = imm_df[(imm_df.i94mode == 1)] \n",
    "imm_df1 = imm_df.groupby(['i94visa','i94port', 'i94addr', 'i94mon', 'i94yr'])['count'].sum().reset_index()\n",
    "imm_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "\n",
    "Three different sources of data are used in this project, immigration records, airport code and demographic data. Naturally, three individual tables will also be created accordingly. The granularity of data from each orginal data source may not be consistent with each other and requires some processing and aggregation. \n",
    "\n",
    "To be specific, \n",
    "- From immigration table, we are interested to know how many people under each type of visas have entered the U.S. via which airport per month. \n",
    "- From airport table, we are interested to know the ariport code, which state it's located and what type of the airport it is. \n",
    "- From demographic table, the granularity of data is a bit different. The demographic table provides information to city level, and we are able to find information such as population, population by race and so on. \n",
    "\n",
    "\n",
    "An illustration of the data model is shown below. \n",
    "![image](./model.png)\n",
    "\n",
    "The immigration and airport table can be merged by airport code.   \n",
    "The immigration table can also be merged with demographic table by state. \n",
    "\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "The steps necessary to pipeline the data into the chosen data model are listed below:  \n",
    "\n",
    "1. Extract: First the original data will be loaded as Pandas dataframes or Spark dataframes, depending on the size of the orginal data. \n",
    "2. Transform: After examing the provided orginal data, it's clear that some level of cleaning is required so that the data can be fed into the data model. In addition, the granularity of some data is also required to be redefined, for which aggregation of records might be helpful. Data cleaning and wrangling happen at this step. \n",
    "2. Load: After data cleaning and necessary aggregation is completed, the processed data can then be fed into the data model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "The data pipelines are built to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.1.1 Immigration data \n",
    "All 12 months of immigration records are read into Spark dataframe. The source data comes in by month, so they will be processed and aggregated by month first and then get combined into one large Spark dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "paths = glob.glob(\"../../data/18-83510-I94-Data-2016/*.sas7bdat\")\n",
    "# read in all 12 months' data, pre-processing on the fly by grouping individual records \n",
    "# by visa category, port, state, month and year \n",
    "for idx,f in enumerate(paths):\n",
    "    if idx == 0:\n",
    "        immigration = spark.read.format('com.github.saurfang.sas.spark').load(f).select('i94visa', 'i94port', 'i94addr', 'i94mon', 'i94yr', 'i94mode', 'count')\n",
    "        immigration = immigration.filter(immigration['i94mode']==1)\n",
    "        immigration = immigration.groupby(['i94visa','i94port', 'i94addr', 'i94mon', 'i94yr']).count()\n",
    "        immigration = immigration.withColumn(\"imm_id\", monotonically_increasing_id()) \\\n",
    "            .withColumnRenamed('i94visa', 'visa_cat') \\\n",
    "            .withColumnRenamed('i94port', 'airport_code') \\\n",
    "            .withColumnRenamed('i94addr', 'state_code') \\\n",
    "            .withColumnRenamed('i94mon', 'month') \\\n",
    "            .withColumnRenamed('i94yr', 'year') \n",
    "    else:\n",
    "        single = spark.read.format('com.github.saurfang.sas.spark').load(f).select('i94visa', 'i94port', 'i94addr', 'i94mon', 'i94yr', 'i94mode', 'count')\n",
    "        single = single.filter(single['i94mode']==1)\n",
    "        single = single.groupby(['i94visa','i94port', 'i94addr', 'i94mon', 'i94yr']).count()\n",
    "        single = single.withColumn(\"imm_id\", monotonically_increasing_id()) \\\n",
    "            .withColumnRenamed('i94visa', 'visa_cat') \\\n",
    "            .withColumnRenamed('i94port', 'airport_code') \\\n",
    "            .withColumnRenamed('i94addr', 'state_code') \\\n",
    "            .withColumnRenamed('i94mon', 'month') \\\n",
    "            .withColumnRenamed('i94yr', 'year') \n",
    "        immigration = immigration.union(single)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(visa_cat=1.0, airport_code='HOU', state_code='TN', month=4.0, year=2016.0, count=316, imm_id=0),\n",
       " Row(visa_cat=2.0, airport_code='EDA', state_code='CA', month=4.0, year=2016.0, count=164, imm_id=1),\n",
       " Row(visa_cat=1.0, airport_code='LVG', state_code='IL', month=4.0, year=2016.0, count=219, imm_id=2),\n",
       " Row(visa_cat=2.0, airport_code='SNA', state_code='CA', month=4.0, year=2016.0, count=491, imm_id=3),\n",
       " Row(visa_cat=2.0, airport_code='MIA', state_code='MS', month=4.0, year=2016.0, count=84, imm_id=4)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.1.2 Airport code data\n",
    "Since the airport code data is small, it'll be processed as Pandas dataframe first and then passed into a Spark dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in airport code data \n",
    "fname ='airport-codes_csv.csv'\n",
    "air_df =  pd.read_csv(fname)\n",
    "\n",
    "# only select airports that are in the U.S. and are not closed \n",
    "air_df = air_df[(air_df.iso_country == 'US') & (air_df.type != 'closed')]\n",
    "\n",
    "# drop records where iata_code is null\n",
    "air_df = air_df.dropna(0,subset = ['iata_code'])\n",
    "\n",
    "# make a new column state_id from iso_region\n",
    "air_df['state_code'] = air_df.iso_region.str[3:]\n",
    "\n",
    "# the columns that are of interest are type, name, iata_code and state_code\n",
    "air_df = air_df[['type', 'name', 'iata_code', 'state_code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pandas dataframe to spark dataframe \n",
    "# LongType() IntegerType() StringType() \n",
    "air_schema = StructType([ StructField(\"type\", StringType(), True)\\\n",
    "                       ,StructField(\"name\", StringType(), True)\\\n",
    "                       ,StructField(\"iata_code\", StringType(), True)\\\n",
    "                       ,StructField(\"state_code\", StringType(), True) ])\n",
    "\n",
    "air_df2 = spark.createDataFrame(air_df,schema=air_schema)\n",
    "\n",
    "airport = air_df2.withColumnRenamed('iata_code', 'airport_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(type='small_airport', name='Ocean Reef Club Airport', airport_code='OCA', state_code='FL'),\n",
       " Row(type='small_airport', name='Pilot Station Airport', airport_code='PQS', state_code='AK'),\n",
       " Row(type='small_airport', name='Crested Butte Airpark', airport_code='CSE', state_code='CO'),\n",
       " Row(type='small_airport', name='LBJ Ranch Airport', airport_code='JCY', state_code='TX'),\n",
       " Row(type='small_airport', name='Metropolitan Airport', airport_code='PMX', state_code='MA')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.1.3 Demographic code data\n",
    "Since the US demographic data is small, it'll be processed as Pandas dataframe first and then passed into a Spark dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read in demographic data\n",
    "fname ='us-cities-demographics.csv'\n",
    "demo_df =  pd.read_csv(fname,sep=';')\n",
    "# transform the long dataset to a wide one so that there's only one record for each city with # for each race\n",
    "demo_df = demo_df.pivot_table(index=['City', 'State', 'Median Age', 'Male Population', 'Female Population', 'Total Population', 'Number of Veterans', 'Foreign-born', 'Average Household Size', 'State Code'],columns='Race', values='Count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# pandas dataframe to spark dataframe \n",
    "demo_df2 =  spark.createDataFrame(demo_df)\n",
    "\n",
    "demographic = demo_df2.withColumn(\"demo_id\", monotonically_increasing_id()) \\\n",
    "            .withColumnRenamed('City', 'city') \\\n",
    "            .withColumnRenamed('State', 'state') \\\n",
    "            .withColumnRenamed('Median Age', 'mage') \\\n",
    "            .withColumnRenamed('Male Population', 'mpopulation') \\\n",
    "            .withColumnRenamed('Female Population', 'fpopulation') \\\n",
    "            .withColumnRenamed('Total Population', 'tpopulation') \\\n",
    "            .withColumnRenamed('Number of Veterans', 'veterans') \\\n",
    "            .withColumnRenamed('Foreign-born', 'fborn') \\\n",
    "            .withColumnRenamed('Average Household Size', 'household') \\\n",
    "            .withColumnRenamed('State Code', 'state_code') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(city='Abilene', state='Texas', mage=31.3, mpopulation=65212.0, fpopulation=60664.0, tpopulation=125876, veterans=9367.0, fborn=8129.0, household=2.64, state_code='TX', American Indian and Alaska Native=1813.0, Asian=2929.0, Black or African-American=14449.0, Hispanic or Latino=33222.0, White=95487.0, demo_id=0),\n",
       " Row(city='Akron', state='Ohio', mage=38.1, mpopulation=96886.0, fpopulation=100667.0, tpopulation=197553, veterans=12878.0, fborn=10024.0, household=2.24, state_code='OH', American Indian and Alaska Native=1845.0, Asian=9033.0, Black or African-American=66551.0, Hispanic or Latino=3684.0, White=129192.0, demo_id=1),\n",
       " Row(city='Alafaya', state='Florida', mage=33.5, mpopulation=39504.0, fpopulation=45760.0, tpopulation=85264, veterans=4176.0, fborn=15842.0, household=2.94, state_code='FL', American Indian and Alaska Native=nan, Asian=10336.0, Black or African-American=6577.0, Hispanic or Latino=34897.0, White=63666.0, demo_id=2),\n",
       " Row(city='Alameda', state='California', mage=41.4, mpopulation=37747.0, fpopulation=40867.0, tpopulation=78614, veterans=4504.0, fborn=18841.0, household=2.52, state_code='CA', American Indian and Alaska Native=1329.0, Asian=27984.0, Black or African-American=7364.0, Hispanic or Latino=8265.0, White=44232.0, demo_id=3),\n",
       " Row(city='Albany', state='Georgia', mage=33.3, mpopulation=31695.0, fpopulation=39414.0, tpopulation=71109, veterans=5409.0, fborn=861.0, household=2.38, state_code='GA', American Indian and Alaska Native=445.0, Asian=650.0, Black or African-American=53440.0, Hispanic or Latino=1783.0, White=17160.0, demo_id=4)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.1 Immigration data checks\n",
    "The unique key in immigration table imm_id is assigned during table build-up by monotonically_increasing_id() so it's naturally unique and not null. \n",
    "Data types of the columns are to be checked by looking at the shcema in order to ensure that all the columns are in the right format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(visa_cat,DoubleType,true),StructField(airport_code,StringType,true),StructField(state_code,StringType,true),StructField(month,DoubleType,true),StructField(year,DoubleType,true),StructField(count,LongType,false),StructField(imm_id,LongType,false)))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigration.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.2 Aiport data checks \n",
    "airport_code is the primary key in this table; needs to check if airport_code is not null and unique. \n",
    "Data types of the columns are to be checked by looking at the shcema in order to ensure that all the columns are in the right format.   \n",
    "It can be confirmed that airport_code is not null and unqiue by following checks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|sum(count)|\n",
      "+----------+\n",
      "|      null|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if any duplicated records in airport data by airport_code\n",
    "import pyspark.sql.functions as f\n",
    "airport.groupBy(airport.airport_code)\\\n",
    "    .count()\\\n",
    "    .where(f.col('count') > 1)\\\n",
    "    .select(f.sum('count'))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[type: string, name: string, airport_code: string, state_code: string]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport.na.drop(subset=[\"airport_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(type,StringType,true),StructField(name,StringType,true),StructField(airport_code,StringType,true),StructField(state_code,StringType,true)))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airport.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2.3 Demographic data checks\n",
    "The unique key in immigration table demo_id is assigned during table build-up by monotonically_increasing_id() so it's naturally unique and not null. \n",
    "Data types of the columns are to be checked by looking at the shcema in order to ensure that all the columns are in the right format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(city,StringType,true),StructField(state,StringType,true),StructField(mage,DoubleType,true),StructField(mpopulation,DoubleType,true),StructField(fpopulation,DoubleType,true),StructField(tpopulation,LongType,true),StructField(veterans,DoubleType,true),StructField(fborn,DoubleType,true),StructField(household,DoubleType,true),StructField(state_code,StringType,true),StructField(American Indian and Alaska Native,DoubleType,true),StructField(Asian,DoubleType,true),StructField(Black or African-American,DoubleType,true),StructField(Hispanic or Latino,DoubleType,true),StructField(White,DoubleType,true),StructField(demo_id,LongType,false)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Data dictionary is attached as a separate file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.4 Write tables to parquet (onto AWS S3)\n",
    "The three tables are to be saved onto AWS S3 for revisit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "# immigration.write.partitionBy(\"month\",\"year\").mode(\"overwrite\").parquet(\"AWS S3 path\")\n",
    "# airport.write.parquet(\"AWS S3 path\")\n",
    "# demographic.write.parquet(\"AWS S3 path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.5 Analysis questions\n",
    "Once the data is fed into the data model. The model can be used to answer some analysis questions mentioned at the beginning of the project. \n",
    "\n",
    "1. Which airport has the most immigrants coming in?\n",
    "2. Which state has the highest immigration rate?\n",
    "3. Which state has the most immigrants coming in as student? What's the immigration rate of that state?\n",
    "4. Which state has the most immigrants coming in for pleasure? What's the immigration rate of that state?\n",
    "\n",
    "First temp views are created based on the three data tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "airport.createOrReplaceTempView(\"airport\")\n",
    "demographic.createOrReplaceTempView(\"demographic\")\n",
    "immigration.createOrReplaceTempView(\"immigration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|airport_code|records|\n",
      "+------------+-------+\n",
      "|         MIA|5080114|\n",
      "+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Which airport has the most immigrants coming in in year 2016?\n",
    "analysis1 = spark.sql(\"\"\"\n",
    "                      SELECT immigration.airport_code, sum(count) as records\n",
    "                      FROM immigration \n",
    "                      JOIN airport \n",
    "                      ON immigration.airport_code = airport.airport_code\n",
    "                      GROUP BY immigration.airport_code\n",
    "                      ORDER BY records DESC\n",
    "                      LIMIT 1\n",
    "                       \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "By looking up in the provided I94 SAS label file, MIA airport refers to the one in Miami, FL. Therefore, the airport that sees the most immigrants comin into the U.S. in 2016 is Miami, FL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+\n",
      "|   city|  state|             irate|\n",
      "+-------+-------+------------------+\n",
      "|Hialeah|Florida|0.7176757408829013|\n",
      "+-------+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Which city has the highest immigration rate?\n",
    "analysis2 = spark.sql(\"\"\"\n",
    "                      SELECT  city, state, (fborn/tpopulation) as irate\n",
    "                      FROM demographic\n",
    "                      ORDER BY irate DESC\n",
    "                      LIMIT 1\n",
    "                       \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The city in the U.S. that has the highest immigration rate is also in Florida, which is Hialeah. The immigration rate here is calculated by foreign borns/total population. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|state_code|records|\n",
      "+----------+-------+\n",
      "|        CA| 282339|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. which state has the most immigrants coming in as student? What's the immigration rate of that state?\n",
    "analysis3_1 = spark.sql(\"\"\"\n",
    "                      SELECT immigration.state_code, sum(immigration.count) as records\n",
    "                      FROM immigration \n",
    "                      WHERE visa_cat = 3 \n",
    "                      GROUP BY immigration.state_code\n",
    "                      ORDER BY records DESC\n",
    "                      LIMIT 1\n",
    "                       \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|state_code|              irate|\n",
      "+----------+-------------------+\n",
      "|        CA|0.30006119457942526|\n",
      "+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis3_2 = spark.sql(\"\"\"\n",
    "                      SELECT state_code, (sum(fborn)/sum(tpopulation)) as irate\n",
    "                      FROM demographic\n",
    "                      WHERE state_code = 'CA'\n",
    "                      GROUP BY state_code\n",
    "                       \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In year 2016, California has the most students coming in; California has a moderately high rate of immigration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|state_code|records|\n",
      "+----------+-------+\n",
      "|        FL|7486788|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Which state has the most immigrants coming in for pleasure? What's the immigration rate of that state?\n",
    "analysis4_1 = spark.sql(\"\"\"\n",
    "                      SELECT immigration.state_code, sum(immigration.count) as records\n",
    "                      FROM immigration \n",
    "                      WHERE visa_cat = 2\n",
    "                      GROUP BY immigration.state_code\n",
    "                      ORDER BY records DESC\n",
    "                      LIMIT 1\n",
    "                       \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "|state_code|              irate|\n",
      "+----------+-------------------+\n",
      "|        FL|0.25057405042244757|\n",
      "+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis4_2 = spark.sql(\"\"\"\n",
    "                      SELECT state_code, (sum(fborn)/sum(tpopulation)) as irate\n",
    "                      FROM demographic\n",
    "                      WHERE state_code = 'FL'\n",
    "                      GROUP BY state_code\n",
    "                       \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In year 2016, most tourists went to Florida for pleasure; the immigration rate of Florida is a little less then that of California. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* The tools used in this project was mainly Spark, which is used to handle large data processing. AWS S3 was also used to store processed tables. Pandas library was also heavily used for data wrangling, explorations, etc..   \n",
    "\n",
    "* Assuming the incoming immigration data will also poccesse a strcuture just like the existing ones, which are saved by month and year, the data then should be updated by month naturally.    \n",
    "\n",
    "* If the data was increased 100x, then it's likely that the processing steps carried out by pandas library will be unable to complete or it will take much longer time to fullfill. In this scenario, one solution might be pre-processing the orginal directly in Spark instead of pandas. Also one may consider using Spark on the cloud.   \n",
    "\n",
    "* If a time is scheduled so that the dashboard to be updated, then this would be a perfect use case for one to utilize Apache Airflow to carry out this assignemnt. Within Apache Airflow, one can set schedules so that the data can be refreshed on a daily basis by 7am every day. Accordingly, the dashboard that's built based on the data will also be updated.     \n",
    " \n",
    "* Presaved OLAP cubes might be able to handle when the data needs to be accessed by a large group of people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
